{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f636a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import tarfile\n",
    "import numbers\n",
    "import threading\n",
    "import queue as Queue\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms.functional as f\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb8f6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir1 = \"../datasets/ICard2/\" #For Ubuntu\n",
    "data_dir1 = \"RegImgs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbecc4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of examples : 3\n"
     ]
    }
   ],
   "source": [
    "img_dir = os.listdir(root_dir1)\n",
    "print('No. of examples :', len(img_dir))\n",
    "#print(img_dir[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d90da2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tra = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.RandomCrop((h, w))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c054cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(root_dir1, transform=tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "37a78c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6828"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6e7b3887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RegImgs', 'ValFNIR', 'ValFPIR']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4cc59acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RegImgs', 'ValFNIR', 'ValFPIR']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(root_dir1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c4a2ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, label = dataset[150]\n",
    "# img_d = torch.permute(img, (1, 2, 0))\n",
    "# print(img_d.shape)\n",
    "\n",
    "# plt.imshow(img_d)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7a499679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(0.))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(img), torch.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "24666923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(255.), tensor(0.))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = img*255\n",
    "torch.max(img), torch.min(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e297f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_img = f.crop(img, 100, 85, 300, 300)\n",
    "# print(new_img.shape)\n",
    "# new_img = torch.permute(new_img, (1, 2, 0))\n",
    "# print(new_img.shape)\n",
    "\n",
    "# plt.imshow(new_img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bf085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ff4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13662f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
